@article{AlphaTensor,
  title={Discovering faster matrix multiplication algorithms with reinforcement learning},
  author={Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Francisco J. R. Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, David Silver, Demis Hassabis and Pushmeet Kohli},
  journal={Nature},
  year={2022},
  volume={610},
  pages={47–53},
  url={https://doi.org/10.1038/s41586-022-05172-4}
}

@article{Vinyals2019GrandmasterLI,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Oriol Vinyals and Igor Babuschkin and Wojciech M. Czarnecki and Micha{\"e}l Mathieu and Andrew Dudzik and Junyoung Chung and David Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and L. Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander Sasha Vezhnevets and R{\'e}mi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom Le Paine and Caglar Gulcehre and Ziyun Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario W{\"u}nsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy P. Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  year={2019},
  volume={575},
  pages={350 - 354},
  url={https://api.semanticscholar.org/CorpusID:204972004}
}

@misc{silver2017masteringchessshogiselfplay,
      title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
      author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
      year={2017},
      eprint={1712.01815},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1712.01815}, 
}

@article{Jumper2021HighlyAP,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={John M. Jumper and Richard Evans and Alexander Pritzel and Tim Green and Michael Figurnov and Olaf Ronneberger and Kathryn Tunyasuvunakool and Russ Bates and Augustin Ž{\'i}dek and Anna Potapenko and Alex Bridgland and Clemens Meyer and Simon A A Kohl and Andy Ballard and Andrew Cowie and Bernardino Romera-Paredes and Stanislav Nikolov and Rishub Jain and Jonas Adler and Trevor Back and Stig Petersen and David Reiman and Ellen Clancy and Michal Zielinski and Martin Steinegger and Michalina Pacholska and Tamas Berghammer and Sebastian Bodenstein and David Silver and Oriol Vinyals and Andrew W. Senior and Koray Kavukcuoglu and Pushmeet Kohli and Demis Hassabis},
  journal={Nature},
  year={2021},
  volume={596},
  pages={583 - 589},
  url={https://api.semanticscholar.org/CorpusID:235959867}
}

@article{
doi:10.1126/science.adi2336,
author = {Remi Lam  and Alvaro Sanchez-Gonzalez  and Matthew Willson  and Peter Wirnsberger  and Meire Fortunato  and Ferran Alet  and Suman Ravuri  and Timo Ewalds  and Zach Eaton-Rosen  and Weihua Hu  and Alexander Merose  and Stephan Hoyer  and George Holland  and Oriol Vinyals  and Jacklynn Stott  and Alexander Pritzel  and Shakir Mohamed  and Peter Battaglia },
title = {Learning skillful medium-range global weather forecasting},
journal = {Science},
volume = {382},
number = {6677},
pages = {1416-1421},
year = {2023},
doi = {10.1126/science.adi2336},
URL = {https://www.science.org/doi/abs/10.1126/science.adi2336},
eprint = {https://www.science.org/doi/pdf/10.1126/science.adi2336},
abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy but does not directly use historical weather data to improve the underlying model. Here, we introduce GraphCast, a machine learning–based method trained directly from reanalysis data. It predicts hundreds of weather variables for the next 10 days at 0.25° resolution globally in under 1 minute. GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclone tracking, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting and helps realize the promise of machine learning for modeling complex dynamical systems. The numerical models used to predict weather are large, complex, and computationally demanding and do not learn from past weather patterns. Lam et al. introduced a machine learning–based method that has been trained directly from reanalysis data of past atmospheric conditions. In this way, the authors were able to quickly predict hundreds of weather variables globally up to 10 days in advance and at high resolution. Their predictions were more accurate than those of traditional weather models in 90\% of tested cases and displayed better severe event prediction for tropical cyclones, atmospheric rivers, and extreme temperatures. —H. Jesse Smith Machine learning leads to better, faster, and cheaper weather forecasting.}}

@misc{zambaldi2024novodesignhighaffinityprotein,
      title={De novo design of high-affinity protein binders with AlphaProteo}, 
      author={Vinicius Zambaldi and David La and Alexander E. Chu and Harshnira Patani and Amy E. Danson and Tristan O. C. Kwan and Thomas Frerix and Rosalia G. Schneider and David Saxton and Ashok Thillaisundaram and Zachary Wu and Isabel Moraes and Oskar Lange and Eliseo Papa and Gabriella Stanton and Victor Martin and Sukhdeep Singh and Lai H. Wong and Russ Bates and Simon A. Kohl and Josh Abramson and Andrew W. Senior and Yilmaz Alguel and Mary Y. Wu and Irene M. Aspalter and Katie Bentley and David L. V. Bauer and Peter Cherepanov and Demis Hassabis and Pushmeet Kohli and Rob Fergus and Jue Wang},
      year={2024},
      eprint={2409.08022},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM},
      url={https://arxiv.org/abs/2409.08022}, 
}

@misc{mirhoseini2020chipplacementdeepreinforcement,
      title={Chip Placement with Deep Reinforcement Learning}, 
      author={Azalia Mirhoseini and Anna Goldie and Mustafa Yazgan and Joe Jiang and Ebrahim Songhori and Shen Wang and Young-Joon Lee and Eric Johnson and Omkar Pathak and Sungmin Bae and Azade Nazi and Jiwoo Pak and Andy Tong and Kavya Srinivasa and William Hang and Emre Tuncer and Anand Babu and Quoc V. Le and James Laudon and Richard Ho and Roger Carpenter and Jeff Dean},
      year={2020},
      eprint={2004.10746},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2004.10746}, 
}

@misc{hoi2018onlinelearningcomprehensivesurvey,
      title={Online Learning: A Comprehensive Survey}, 
      author={Steven C. H. Hoi and Doyen Sahoo and Jing Lu and Peilin Zhao},
      year={2018},
      eprint={1802.02871},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.02871}, 
}

@article{
doi:10.1126/science.adg7492,
author = {Jun Cheng  and Guido Novati  and Joshua Pan  and Clare Bycroft  and Akvilė Žemgulytė  and Taylor Applebaum  and Alexander Pritzel  and Lai Hong Wong  and Michal Zielinski  and Tobias Sargeant  and Rosalia G. Schneider  and Andrew W. Senior  and John Jumper  and Demis Hassabis  and Pushmeet Kohli  and Žiga Avsec },
title = {Accurate proteome-wide missense variant effect prediction with AlphaMissense},
journal = {Science},
volume = {381},
number = {6664},
pages = {eadg7492},
year = {2023},
doi = {10.1126/science.adg7492},
URL = {https://www.science.org/doi/abs/10.1126/science.adg7492},
eprint = {https://www.science.org/doi/pdf/10.1126/science.adg7492},
abstract = {The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present AlphaMissense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89\% of missense variants as either likely benign or likely pathogenic. Single–amino acid changes in proteins sometimes have little effect but can often lead to problems in protein folding, activity, or stability. Only a small fraction of variants have been experimentally investigated, but there are vast amounts of biological sequence data that are suitable for use as training data for machine learning approaches. Cheng et al. developed AlphaMissense, a deep learning model that builds on the protein structure prediction tool AlphaFold2 (see the Perspective by Marsh and Teichmann). The model is trained on population frequency data and uses sequence and predicted structural context, all of which contribute to its performance. The authors evaluated the model against related methods using clinical databases not included in the training and demonstrated agreement with multiplexed assays of variant effect. Predictions for all single–amino acid substitutions in the human proteome are provided as a community resource. —Michael A. Funk AlphaFold fine-tuned on human and primate population variant frequency databases predicts variant pathogenicity.}}

@misc{villegas2022phenakivariablelengthvideo,
      title={Phenaki: Variable Length Video Generation From Open Domain Textual Description}, 
      author={Ruben Villegas and Mohammad Babaeizadeh and Pieter-Jan Kindermans and Hernan Moraldo and Han Zhang and Mohammad Taghi Saffar and Santiago Castro and Julius Kunze and Dumitru Erhan},
      year={2022},
      eprint={2210.02399},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.02399}, 
}

@article{Schrittwieser_2020,
   title={Mastering Atari, Go, chess and shogi by planning with a learned model},
   volume={588},
   ISSN={1476-4687},
   url={http://dx.doi.org/10.1038/s41586-020-03051-4},
   DOI={10.1038/s41586-020-03051-4},
   number={7839},
   journal={Nature},
   publisher={Springer Science and Business Media LLC},
   author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
   year={2020},
   month=dec, pages={604–609} }

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@book{prince2023understanding,
        author = "Simon J.D. Prince",
        title = "Understanding Deep Learning",
        publisher = "The MIT Press",
        year = 2023,
        url = "http://udlbook.com"
    }

@book{Sutton1998,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018 }
}

@misc{papamarkou2024positiontopologicaldeeplearning,
      title={Position: Topological Deep Learning is the New Frontier for Relational Learning}, 
      author={Theodore Papamarkou and Tolga Birdal and Michael Bronstein and Gunnar Carlsson and Justin Curry and Yue Gao and Mustafa Hajij and Roland Kwitt and Pietro Liò and Paolo Di Lorenzo and Vasileios Maroulas and Nina Miolane and Farzana Nasrin and Karthikeyan Natesan Ramamurthy and Bastian Rieck and Simone Scardapane and Michael T. Schaub and Petar Veličković and Bei Wang and Yusu Wang and Guo-Wei Wei and Ghada Zamzmi},
      year={2024},
      eprint={2402.08871},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.08871}, 
}

@misc{hajij2023topologicaldeeplearninggoing,
      title={Topological Deep Learning: Going Beyond Graph Data}, 
      author={Mustafa Hajij and Ghada Zamzmi and Theodore Papamarkou and Nina Miolane and Aldo Guzmán-Sáenz and Karthikeyan Natesan Ramamurthy and Tolga Birdal and Tamal K. Dey and Soham Mukherjee and Shreyas N. Samaga and Neal Livesay and Robin Walters and Paul Rosen and Michael T. Schaub},
      year={2023},
      eprint={2206.00606},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2206.00606}, 
}

@book{10.5555/3384132,
author = {Graesser, Laura and Keng, Wah Loon},
title = {Foundations of Deep Reinforcement Learning: Theory and Practice in Python},
year = {2019},
isbn = {0135172381},
publisher = {Addison-Wesley Professional},
edition = {1st},
abstract = {The Contemporary Introduction to Deep Reinforcement Learning that Combines Theory and Practice, Deep reinforcement learning (deep RL) combines deep learning and reinforcement learning, in which artificial agents learn to solve sequential decision-making problems. In the past decade deep RL has achieved remarkable results on a range of problems, from single and multiplayer games—such as Go, Atari games, and DotA 2—to robotics. Foundations of Deep Reinforcement Learning is an introduction to deep RL that uniquely combines both theory and implementation. It starts with intuition, then carefully explains the theory of deep RL algorithms, discusses implementations in its companion software library SLM Lab, and finishes with the practical details of getting deep RL to work. This guide is ideal for both computer science students and software engineers who are familiar with basic machine learning concepts and have a working understanding of Python. · Understand each key aspect of a deep RL problem · Explore policy- and value-based algorithms, including REINFORCE, SARSA, DQN, Double DQN, and Prioritized Experience Replay (PER) · Delve into combined algorithms, including Actor-Critic and Proximal Policy Optimization (PPO) · Understand how algorithms can be parallelized synchronously and asynchronously · Run algorithms in SLM Lab and learn the practical implementation details for getting deep RL to work · Explore algorithm benchmark results with tuned hyperparameters · Understand how deep RL environments are designed, Register your book for convenient access to downloads, updates, and/or corrections as they become available. See inside book for details.}
}

@misc{grathwohl2018backpropagationvoidoptimizingcontrol,
      title={Backpropagation through the Void: Optimizing control variates for black-box gradient estimation}, 
      author={Will Grathwohl and Dami Choi and Yuhuai Wu and Geoffrey Roeder and David Duvenaud},
      year={2018},
      eprint={1711.00123},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.00123}, 
}

@book{Thomson_2013, place={Cambridge}, title={Modern Particle Physics}, publisher={Cambridge University Press}, author={Thomson, Mark}, year={2013}} 

@PHDTHESIS{20.500.11850/476304,
	copyright = {In Copyright - Non-Commercial Use Permitted},
	year = {2020},
	type = {Doctoral Thesis},
	author = {Novati, Guido},
	size = {175 p.},
	language = {en},
	address = {Zurich},
	publisher = {ETH Zurich},
	DOI = {10.3929/ethz-b-000476304},
	title = {Flow modeling and control through deep reinforcement learning},
	school = {ETH Zurich}
}

@misc{holzleitner2020convergenceproofactorcriticmethods,
      title={Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER}, 
      author={Markus Holzleitner and Lukas Gruber and José Arjona-Medina and Johannes Brandstetter and Sepp Hochreiter},
      year={2020},
      eprint={2012.01399},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2012.01399}, 
}

@misc{fan2020theoreticalanalysisdeepqlearning,
      title={A Theoretical Analysis of Deep Q-Learning}, 
      author={Jianqing Fan and Zhaoran Wang and Yuchen Xie and Zhuoran Yang},
      year={2020},
      eprint={1901.00137},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.00137}, 
}

@misc{hoi2018onlinelearningcomprehensivesurvey,
      title={Online Learning: A Comprehensive Survey}, 
      author={Steven C. H. Hoi and Doyen Sahoo and Jing Lu and Peilin Zhao},
      year={2018},
      eprint={1802.02871},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.02871}, 
}

@misc{bird2025backpropagationtimenetworkslongterm,
      title={Backpropagation Through Time For Networks With Long-Term Dependencies}, 
      author={George Bird and Maxim E. Polivoda},
      year={2025},
      eprint={2103.15589},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.15589}, 
}

@article{journals/neco/WilliamsZ89,
  added-at = {2023-08-28T00:00:00.000+0200},
  author = {Williams, Ronald J. and Zipser, David},
  biburl = {https://www.bibsonomy.org/bibtex/271e397fbd3c9aae7b0556d3024813470/dblp},
  ee = {https://www.wikidata.org/entity/Q114872251},
  interhash = {17f3915c54c21aa4faf9376aa019efe1},
  intrahash = {71e397fbd3c9aae7b0556d3024813470},
  journal = {Neural Comput.},
  keywords = {dblp},
  number = 2,
  pages = {270-280},
  timestamp = {2024-04-08T19:33:58.000+0200},
  title = {A Learning Algorithm for Continually Running Fully Recurrent Neural Networks.},
  url = {http://dblp.uni-trier.de/db/journals/neco/neco1.html#WilliamsZ89},
  volume = 1,
  year = 1989
}

@misc{damadi2023backpropagationalgorithmmathstudent,
      title={The Backpropagation algorithm for a math student}, 
      author={Saeed Damadi and Golnaz Moharrer and Mostafa Cham},
      year={2023},
      eprint={2301.09977},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2301.09977}, 
}

@misc{abbas2023quantumbackpropagationinformationreuse,
      title={On quantum backpropagation, information reuse, and cheating measurement collapse}, 
      author={Amira Abbas and Robbie King and Hsin-Yuan Huang and William J. Huggins and Ramis Movassagh and Dar Gilboa and Jarrod R. McClean},
      year={2023},
      eprint={2305.13362},
      archivePrefix={arXiv},
      primaryClass={quant-ph},
      url={https://arxiv.org/abs/2305.13362}, 
}

@misc{irie2024exploringpromiselimitsrealtime,
      title={Exploring the Promise and Limits of Real-Time Recurrent Learning}, 
      author={Kazuki Irie and Anand Gopalakrishnan and Jürgen Schmidhuber},
      year={2024},
      eprint={2305.19044},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.19044}, 
}

@article{JMLR:v24:23-0367,
  author  = {Khurram Javed and Haseeb Shah and Richard S. Sutton and Martha White},
  title   = {Scalable Real-Time Recurrent Learning Using Columnar-Constructive Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {256},
  pages   = {1--34},
  url     = {http://jmlr.org/papers/v24/23-0367.html}
}

@misc{noel2021onlinereinforcementlearningsparse,
      title={Online reinforcement learning with sparse rewards through an active inference capsule}, 
      author={Alejandro Daniel Noel and Charel van Hoof and Beren Millidge},
      year={2021},
      eprint={2106.02390},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.02390}, 
}

@misc{noel2021onlinereinforcementlearningsparse,
      title={Online reinforcement learning with sparse rewards through an active inference capsule}, 
      author={Alejandro Daniel Noel and Charel van Hoof and Beren Millidge},
      year={2021},
      eprint={2106.02390},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2106.02390}, 
}

@article {Li2020.05.16.100057,
	author = {Li, Xiaoxiao and Zhou, Yuan and Dvornek, Nicha and Zhang, Muhan and Gao, Siyuan and Zhuang, Juntang and Scheinost, Dustin and Staib, Lawrence and Ventola, Pamela and Duncan, James},
	title = {BrainGNN: Interpretable Brain Graph Neural Network for fMRI Analysis},
	elocation-id = {2020.05.16.100057},
	year = {2021},
	doi = {10.1101/2020.05.16.100057},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Understanding which brain regions are related to a specific neurological disorder or cognitive stimuli has been an important area of neuroimaging research. We propose BrainGNN, a graph neural network (GNN) framework to analyze functional magnetic resonance images (fMRI) and discover neurological biomarkers. Considering the special property of brain graphs, we design novel ROI-aware graph convolutional (Ra-GConv) layers that leverage the topological and functional information of fMRI. Motivated by the need for transparency in medical image analysis, our BrainGNN contains ROI-selection pooling layers (R-pool) that highlight salient ROIs (nodes in the graph), so that we can infer which ROIs are important for prediction. Furthermore, we propose regularization terms{\textemdash}unit loss, topK pooling (TPK) loss and group-level consistency (GLC) loss{\textemdash}on pooling results to encourage reasonable ROI-selection and provide flexibility to encourage either fully individual- or patterns that agree with group-level data. We apply the BrainGNN framework on two independent fMRI datasets: an Autism Spectrum Disorder (ASD) fMRI dataset and data from the Human Connectome Project (HCP) 900 Subject Release. We investigate different choices of the hyper-parameters and show that BrainGNN outperforms the alternative fMRI image analysis methods in terms of four different evaluation metrics. The obtained community clustering and salient ROI detection results show a high correspondence with the previous neuroimaging-derived evidence of biomarkers for ASD and specific task states decoded for HCP. We will make BrainGNN codes public available after acceptance.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2021/06/07/2020.05.16.100057},
	eprint = {https://www.biorxiv.org/content/early/2021/06/07/2020.05.16.100057.full.pdf},
	journal = {bioRxiv}
}

@article{ROBINSON2022333,
title = {Physics guided neural networks for modelling of non-linear dynamics},
journal = {Neural Networks},
volume = {154},
pages = {333-345},
year = {2022},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2022.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0893608022002854},
author = {Haakon Robinson and Suraj Pawar and Adil Rasheed and Omer San},
keywords = {Physics guided neural networks, Non-linear dynamics, Ordinary differential equations},
abstract = {The success of the current wave of artificial intelligence can be partly attributed to deep neural networks, which have proven to be very effective in learning complex patterns from large datasets with minimal human intervention. However, it is difficult to train these models on complex dynamical systems from data alone due to their low data efficiency and sensitivity to hyperparameters and initialisation. This work demonstrates that injection of partially known information at an intermediate layer in a DNN can improve model accuracy, reduce model uncertainty, and yield improved convergence during the training. The value of these physics-guided neural networks has been demonstrated by learning the dynamics of a wide variety of nonlinear dynamical systems represented by five well-known equations in nonlinear systems theory: the Lotka–Volterra, Duffing, Van der Pol, Lorenz, and Henon–Heiles systems.}
}

@article{SANSMUNTADAS201984,
title = {Path planning and guidance for underactuated vehicles with limited field-of-view},
journal = {Ocean Engineering},
volume = {174},
pages = {84-95},
year = {2019},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2019.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0029801818310333},
author = {Albert Sans-Muntadas and Eleni Kelasidi and Kristin Y. Pettersen and Edmund Brekke},
keywords = {FOV constraint, Landmark based navigation, Path planning, Guidance, Underactuated vehicle},
abstract = {When GPS is not available, autonomous vehicles can obtain navigation information by observing a source with a camera or an acoustic system mounted on the frame of the vehicle. This information can be used in the navigation and to overcome the lack of other sources of positioning. However, these systems often have a limited range and angular FOV. Due to this restriction, motion along some paths will make it impossible to obtain the necessary navigation information as the source is no longer in the vehicle's FOV. This paper proposes both a path planning approach and a guidance control law that allows the vehicle to preserve landmarks that are critical for the navigation inside the FOV while at the same time converging to the proposed path. The suggested approach is experimentally validated by implementation in an autonomous underwater vehicle.}
}

@article{CHEN2024117199,
title = {Algorithms for dynamic control of a deep-sea mining vehicle based on deep reinforcement learning},
journal = {Ocean Engineering},
volume = {298},
pages = {117199},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117199},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824005365},
author = {Qihang Chen and Jianmin Yang and Wenhua Zhao and Longbin Tao and Jinghang Mao and Zhiyuan Li},
keywords = {Deep-sea mining, Dynamic obstacle avoidance, Deep reinforcement learning, Hyperparameter optimization, Artificial intelligence},
abstract = {Deep-sea mining aims to extract mineral resources from the ocean seabed, necessitating advanced vehicles for efficient operations. These vehicles, essential for exploiting the vast underwater resources, require sophisticated navigation. The primary challenge in deep-sea navigation is the absence of satisfactory algorithms that are capable of handling the complexity and unpredictability in deep-sea environment. This research deploys advanced deep reinforcement learning algorithms, to enable dynamic control in the deep-sea navigation - which was previously challenging when using conventional methods. These algorithms with detailed optimization of the hyperparameters have been implemented on a four-track deep-sea mining vehicle, demonstrating good performance in dynamic avoidance of obstacles that are randomly deployed.}
}

@article{SANSMUNTADAS2016199,
title = {Vision Restricted Path Planning and Control for Underactuated Vehicles},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {23},
pages = {199-206},
year = {2016},
note = {10th IFAC Conference on Control Applications in Marine SystemsCAMS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.10.343},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316319309},
author = {Albert Sans-Muntadas and Kristin Y. Pettersen and Edmund Brekke},
keywords = {FOV Constraint, Landmark Navigation, Path Planning, Guidance, Underactuated Vehicle},
abstract = {Abstract:
Autonomous vehicles can obtain navigation information by observing a source with a camera or an acoustic system mounted on the frame of the vehicle. This information properly fused provides navigation information that can overcome the lack of other sources of positioning. However, these systems often have a limited angular field-of-view (FOV). Due to this restriction, motion along some paths will make it impossible to obtain the necessary navigation information as the source is no longer in the vehicle’s FOV. This paper proposes both a path planning approach and a guidance control law that allows the vehicle to preserve a certain object or feature inside the FOV while at the same time converging to the proposed path.}
}

@article{JMLR:v24:23-0367,
  author  = {The Microbial World: Foundation of the Biosphere: This report is based on an American Academy of Microbiology colloquium held January 19-21, 1996, in Palm Coast, Florida. The colloquium was supported by the National Science Foundation, the National Oceanic and Atmospheric Administration of the U.S. Department of Commerce, the U.S. Department of Energy, and the American Society for Microbiology; 1997. Available from: https://www.ncbi.nlm.nih.gov/books/NBK562919/ doi: 10.1128/AAMCol.19Jan.1996},
  title   = {Scalable Real-Time Recurrent Learning Using Columnar-Constructive Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {256},
  pages   = {1--34},
  url     = {10.1128/AAMCol.19Jan.1996}
}

@book{book,
author = {Lincoln, D.},
year = {2012},
month = {01},
pages = {1-567},
title = {Understanding the universe from quarks to the cosmos, revised edition},
isbn = {9789814374446},
doi = {10.1142/8313}
}

@article{Best_2023,
   title={The LOFAR Two-metre Sky Survey: Deep Fields data release 1. V. Survey description, source classifications, and host galaxy properties},
   volume={523},
   ISSN={1365-2966},
   url={http://dx.doi.org/10.1093/mnras/stad1308},
   DOI={10.1093/mnras/stad1308},
   number={2},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Best, P N and Kondapally, R and Williams, W L and Cochrane, R K and Duncan, K J and Hale, C L and Haskell, P and Małek, K and McCheyne, I and Smith, D J B and Wang, L and Botteon, A and Bonato, M and Bondi, M and Rivera, G Calistro and Gao, F and Gürkan, G and Hardcastle, M J and Jarvis, M J and Mingo, B and Miraghaei, H and Morabito, L K and Nisbet, D and Prandoni, I and Röttgering, H J A and Sabater, J and Shimwell, T and Tasse, C and van Weeren, R},
   year={2023},
   month=apr, pages={1729–1755} }

@Article{s22010247,
AUTHOR = {Laconte, Johann and Kasmi, Abderrahim and Aufrère, Romuald and Vaidis, Maxime and Chapuis, Roland},
TITLE = {A Survey of Localization Methods for Autonomous Vehicles in Highway Scenarios},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {247},
URL = {https://www.mdpi.com/1424-8220/22/1/247},
PubMedID = {35009790},
ISSN = {1424-8220},
ABSTRACT = {In the context of autonomous vehicles on highways, one of the first and most important tasks is to localize the vehicle on the road. For this purpose, the vehicle needs to be able to take into account the information from several sensors and fuse them with data coming from road maps. The localization problem on highways can be distilled into three main components. The first one consists of inferring on which road the vehicle is currently traveling. Indeed, Global Navigation Satellite Systems are not precise enough to deduce this information by themselves, and thus a filtering step is needed. The second component consists of estimating the vehicle’s position in its lane. Finally, the third and last one aims at assessing on which lane the vehicle is currently driving. These two last components are mandatory for safe driving as actions such as overtaking a vehicle require precise information about the current localization of the vehicle. In this survey, we introduce a taxonomy of the localization methods for autonomous vehicles in highway scenarios. We present each main component of the localization process, and discuss the advantages and drawbacks of the associated state-of-the-art methods.},
DOI = {10.3390/s22010247}
}

@article{Wykes_2014,
   title={Filaments in the southern giant lobe of Centaurus A: constraints on nature and origin from modelling and GMRT observations},
   volume={442},
   ISSN={1365-2966},
   url={http://dx.doi.org/10.1093/mnras/stu1033},
   DOI={10.1093/mnras/stu1033},
   number={4},
   journal={Monthly Notices of the Royal Astronomical Society},
   publisher={Oxford University Press (OUP)},
   author={Wykes, Sarka and Intema, Huib T. and Hardcastle, Martin J. and Achterberg, Abraham and Jones, Thomas W. and Jerjen, Helmut and Orrú, Emanuela and Lazarian, Alex and Shimwell, Timothy W. and Wise, Michael W. and Kronberg, Philipp P.},
   year={2014},
   month=jun, pages={2867–2882} }

@article{Deng_2013,
   title={Interplanetary spacecraft navigation using pulsars},
   volume={52},
   ISSN={0273-1177},
   url={http://dx.doi.org/10.1016/j.asr.2013.07.025},
   DOI={10.1016/j.asr.2013.07.025},
   number={9},
   journal={Advances in Space Research},
   publisher={Elsevier BV},
   author={Deng, X.P. and Hobbs, G. and You, X.P. and Li, M.T. and Keith, M.J. and Shannon, R.M. and Coles, W. and Manchester, R.N. and Zheng, J.H. and Yu, X.Z. and Gao, D. and Wu, X. and Chen, D.},
   year={2013}}   

@book{ marl-book,
  author = {Stefano V. Albrecht and Filippos Christianos and Lukas Sch\"afer},
  title = {Multi-Agent Reinforcement Learning: Foundations and Modern Approaches},
  publisher = {MIT Press},
  year = {2024},
  url = {https://www.marl-book.com}
}

@misc{zhang2023ultralowcostsmartphonemicroscopy,
      title={Towards ultra-low-cost smartphone microscopy}, 
      author={Haoran Zhang and Weiyi Zhang and Zirui Zuo and Jianlong Yang},
      year={2023},
      eprint={2312.11479},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2312.11479}, 
}


@misc{liu2025physicsinformedgenerativerealtimelensfree,
      title={Physics-informed generative real-time lens-free imaging}, 
      author={Ronald B. Liu and Zhe Liu and Max G. A. Wolf and Krishna P. Purohit and Gregor Fritz and Yi Feng and Carsten G. Hansen and Pierre O. Bagnaninchi and Xavier Casadevall i Solvas and Yunjie Yang},
      year={2025},
      eprint={2403.07786},
      archivePrefix={arXiv},
      primaryClass={physics.optics},
      url={https://arxiv.org/abs/2403.07786}, 
}

@misc{michelucci2022introductionautoencoders,
      title={An Introduction to Autoencoders}, 
      author={Umberto Michelucci},
      year={2022},
      eprint={2201.03898},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.03898}, 
}

@misc{bengio2014representationlearningreviewnew,
      title={Representation Learning: A Review and New Perspectives}, 
      author={Yoshua Bengio and Aaron Courville and Pascal Vincent},
      year={2014},
      eprint={1206.5538},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1206.5538}, 
}

@misc{perelman2003ricciflowsurgerythreemanifolds,
      title={Ricci flow with surgery on three-manifolds}, 
      author={Grisha Perelman},
      year={2003},
      eprint={math/0303109},
      archivePrefix={arXiv},
      primaryClass={math.DG},
      url={https://arxiv.org/abs/math/0303109}, 
}

@misc{perelman2002entropyformularicciflow,
      title={The entropy formula for the Ricci flow and its geometric applications}, 
      author={Grisha Perelman},
      year={2002},
      eprint={math/0211159},
      archivePrefix={arXiv},
      primaryClass={math.DG},
      url={https://arxiv.org/abs/math/0211159}, 
}

@article{JMLR:v23:21-0368,
  author  = {Zhong Li and Jiequn Han and Weinan E and Qianxiao Li},
  title   = {Approximation and Optimization Theory for Linear Continuous-Time Recurrent Neural Networks},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {42},
  pages   = {1--85},
  url     = {http://jmlr.org/papers/v23/21-0368.html}
}

@article{10.5555/1953048.2021064,
author = {Hahsler, Michael and Chelluboina, Sudheer and Hornik, Kurt and Buchta, Christian},
title = {The arules R-Package Ecosystem: Analyzing Interesting Patterns from Large Transaction Data Sets},
year = {2011},
issue_date = {2/1/2011},
publisher = {JMLR.org},
volume = {12},
number = {null},
issn = {1532-4435},
abstract = {This paper describes the ecosystem of R add-on packages developed around the infrastructure provided by the package arules. The packages provide comprehensive functionality for analyzing interesting patterns including frequent itemsets, association rules, frequent sequences and for building applications like associative classification. After discussing the ecosystem's design we illustrate the ease of mining and visualizing rules with a short example.},
journal = {J. Mach. Learn. Res.},
month = jul,
pages = {2021–2025},
numpages = {5}
}

